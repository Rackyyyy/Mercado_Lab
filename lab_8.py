# -*- coding: utf-8 -*-
"""LAB 8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eOO2RqcZBIgoOnIlLnb1IzenRFrhKm1t
"""

!pip install -U imbalanced-learn

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from imblearn.over_sampling import SMOTE
from google.colab import files

uploaded = files.upload()
filename = list(uploaded.keys())[0]
df = pd.read_csv(filename)

# --- Feature Engineering ---
if 'date' in df.columns:
    df['date'] = pd.to_datetime(df['date'], format='%m%d%H%M', errors='coerce')
    df['hour'] = df['date'].dt.hour
    df['day_of_week'] = df['date'].dt.dayofweek
    df['month'] = df['date'].dt.month
else:
    raise ValueError("Dataset does not contain a 'date' column.")

if 'delay' in df.columns:
    df['delayed'] = (df['delay'] > 15).astype(int)
else:
    raise ValueError("Dataset does not contain a 'delay' column.")

if 'origin' in df.columns:
    top_airports = df['origin'].value_counts().nlargest(2).index.tolist()
    print("Selected Top 2 Airports for Modeling:", top_airports)
else:
    raise ValueError("Dataset does not contain an 'origin' column.")

# --- Process each selected airport individually ---
for airport in top_airports:
    print(f"\n Processing Origin Airport: {airport}")

    # Filter dataset
    df_airport = df[df['origin'] == airport].copy()

    # One-hot encode categorical 'destination'
    df_airport = pd.get_dummies(df_airport, columns=['destination'], drop_first=True)

    # Define features and target
    X = df_airport.drop(columns=['delay', 'date', 'delayed', 'origin'])
    y = df_airport['delayed']

    # Split dataset
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y)

    # Handle missing values
    if X_train.isnull().values.any():
        X_train.fillna(X_train.median(), inplace=True)
        X_test.fillna(X_test.median(), inplace=True)

    # --- Model without SMOTE ---
    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    # Evaluation
    print("\n Evaluation Before SMOTE:")
    print(f"Accuracy: {accuracy_score(y_test, y_pred):.4f}")
    print("Classification Report:\n", classification_report(y_test, y_pred))

    sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')
    plt.title(f'Confusion Matrix - {airport} (Before SMOTE)')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.show()

    # --- Apply SMOTE to handle class imbalance ---
    smote = SMOTE(random_state=42)
    X_resampled, y_resampled = smote.fit_resample(X_train, y_train)

    # Retrain model
    model.fit(X_resampled, y_resampled)
    y_pred_resampled = model.predict(X_test)

    # Evaluation after SMOTE
    print("\n Evaluation After SMOTE:")
    print(f"Accuracy: {accuracy_score(y_test, y_pred_resampled):.4f}")
    print("Classification Report:\n", classification_report(y_test, y_pred_resampled))

    sns.heatmap(confusion_matrix(y_test, y_pred_resampled), annot=True, fmt='d', cmap='Greens')
    plt.title(f'Confusion Matrix - {airport} (After SMOTE)')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.show()

    # --- Feature Importance ---
    feature_importances = pd.Series(model.feature_importances_, index=X.columns)
    feature_importances.nlargest(10).plot(kind='barh', color='skyblue')
    plt.title(f'Top 10 Features - {airport}')
    plt.xlabel('Importance Score')
    plt.show()

# --- Overall Delay Distribution ---
plt.figure(figsize=(8, 5))
plt.hist(df['delay'], bins=30, color='salmon', edgecolor='black')
plt.title("Distribution of Flight Delays")
plt.xlabel("Delay (minutes)")
plt.ylabel("Number of Flights")
plt.show()